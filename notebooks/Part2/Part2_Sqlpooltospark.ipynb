{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "df: org.apache.spark.sql.DataFrame = [identifierid: string, level: int ... 19 more fields]"
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%spark\n",
        "val df = spark.read.sqlanalytics(\"aaasqlpool.dbo.dataflow_table\") \n",
        "df.write.mode(\"overwrite\").saveAsTable(\"default.dataflowsparkwowdataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        ""
      ],
      "attachments": {}
    }
  ]
}